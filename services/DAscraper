from playwright.sync_api import sync_playwright
import time
from datetime import datetime, timedelta
import re

def parse_address(full_address):
    """
    Parse address from geocoder format: "12 Aquila Court, MERMAID WATERS, 4218"
    Returns: (street_number, street_name, street_type, suburb)
    """
    try:
        # Split by comma
        parts = [p.strip() for p in full_address.split(',')]
        
        if len(parts) < 2:
            return None, None, None, None
        
        # First part: street number + street name + street type
        street_part = parts[0].strip()
        # Second part: suburb
        suburb = parts[1].strip().upper()
        
        # Parse street part - split by spaces
        street_tokens = street_part.split()
        
        if len(street_tokens) < 3:
            # Need at least: number, name, type
            return None, None, None, None
        
        # First token is street number
        street_number = street_tokens[0]
        
        # Last token is street type
        street_type = street_tokens[-1]
        
        # Everything in between is street name
        street_name = ' '.join(street_tokens[1:-1])
        
        return street_number, street_name, street_type, suburb
        
    except Exception as e:
        print(f"Error parsing address: {e}")
        return None, None, None, None


def scrape_pdonline_with_details(street_name, street_type="Avenue", street_number=None, months_back=12, debug=True):
    """
    Scrape Gold Coast PDOnline for development applications with detailed information.
    
    Args:
        street_name: Street name to search (e.g., "Peerless")
        street_type: Street type (e.g., "Avenue", "Street", "Road")
        street_number: Optional street number
        months_back: Only get detailed info for applications within this many months (default: 12)
        debug: Enable verbose debugging output
    
    Returns:
        List of dictionaries containing DA information with details
    """
    
    cutoff_date = datetime.now() - timedelta(days=months_back * 30)
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)  # Headless for production
        context = browser.new_context()
        page = context.new_page()
        page.set_default_timeout(30000)
        
        try:
            if debug:
                print("="*80)
                print("STEP 1: NAVIGATING TO SEARCH PAGE")
                print("="*80)
            
            page.goto('https://cogc.cloud.infor.com/ePathway/epthprod/Web/default.aspx')
            page.wait_for_load_state('networkidle')
            time.sleep(1)
            if debug:
                print("  ✓ Loaded homepage")
            
            page.click('a:has-text("All applications")')
            page.wait_for_load_state('networkidle')
            time.sleep(1)
            if debug:
                print("  ✓ Clicked 'All applications'")
            
            page.click('input#ctl00_MainBodyContent_mDataList_ctl03_mDataGrid_ctl02_ctl00')
            time.sleep(1)
            if debug:
                print("  ✓ Selected radio button")
            
            page.click('input[type="submit"][value="Next"]')
            page.wait_for_load_state('networkidle')
            time.sleep(1)
            if debug:
                print("  ✓ Clicked Next")
            
            page.wait_for_selector('a:has-text("Address search")')
            page.click('a:has-text("Address search")')
            time.sleep(1)
            if debug:
                print("  ✓ Clicked Address search tab")
            
            if debug:
                print("\n" + "="*80)
                print("STEP 2: FILLING SEARCH FORM")
                print("="*80)
            
            page.wait_for_selector('#ctl00_MainBodyContent_mGeneralEnquirySearchControl_mTabControl_ctl09_mStreetNameTextBox')
            
            if street_number:
                page.fill('#ctl00_MainBodyContent_mGeneralEnquirySearchControl_mTabControl_ctl09_mStreetNumberTextBox', str(street_number))
                if debug:
                    print("  ✓ Filled street number: " + str(street_number))
            
            page.fill('#ctl00_MainBodyContent_mGeneralEnquirySearchControl_mTabControl_ctl09_mStreetNameTextBox', street_name)
            if debug:
                print("  ✓ Filled street name: " + street_name)
            
            page.select_option('#ctl00_MainBodyContent_mGeneralEnquirySearchControl_mTabControl_ctl09_mStreetTypeDropDown', street_type)
            if debug:
                print("  ✓ Selected street type: " + street_type)
            
            page.click('#ctl00_MainBodyContent_mGeneralEnquirySearchControl_mSearchButton')
            page.wait_for_load_state('networkidle')
            time.sleep(2)
            if debug:
                print("  ✓ Submitted search")
            
            if debug:
                print("\n" + "="*80)
                print("STEP 3: PARSING RESULTS PAGE")
                print("="*80)
            
            if 'EnquirySummaryView' not in page.url:
                print("✗ ERROR: Not on results page")
                print("  Current URL: " + page.url)
                browser.close()
                return []
            
            if debug:
                print("  ✓ On results page: " + page.url)
            
            results_url = page.url
            page.wait_for_selector('table#gridResults', timeout=5000)
            
            app_links = []
            rows = page.query_selector_all('table#gridResults tr.ContentPanel, table#gridResults tr.AlternateContentPanel')
            
            if debug:
                print("  ✓ Found " + str(len(rows)) + " result rows")
                print("\n" + "="*80)
                print("STEP 4: EXTRACTING BASIC INFO FROM ALL ROWS")
                print("="*80)
            
            for idx, row in enumerate(rows, 1):
                try:
                    cells = row.query_selector_all('td')
                    if len(cells) < 5:
                        continue
                    
                    app_number = cells[0].inner_text().strip()
                    lodgement_date_str = cells[1].inner_text().strip()
                    location = cells[2].inner_text().strip()
                    app_type = cells[3].inner_text().strip()
                    suburb = cells[4].inner_text().strip()
                    
                    link = cells[0].query_selector('a')
                    href = link.get_attribute('href') if link else None
                    
                    if debug:
                        print("\n  Row " + str(idx) + ":")
                        print("    App Number: " + app_number)
                        print("    Date: " + lodgement_date_str)
                        print("    Location: " + location[:50] + "...")
                        print("    Type: " + app_type)
                        print("    Has link: " + str(href is not None))
                    
                    try:
                        lodgement_date = datetime.strptime(lodgement_date_str, '%d/%m/%Y')
                        within_range = lodgement_date >= cutoff_date
                    except:
                        lodgement_date = None
                        within_range = False
                    
                    app_links.append({
                        'application_number': app_number,
                        'lodgement_date': lodgement_date_str,
                        'location': location,
                        'application_type': app_type,
                        'suburb': suburb,
                        'href': href,
                        'within_range': within_range,
                        'lodgement_date_obj': lodgement_date
                    })
                    
                    if debug and within_range:
                        print("    ✓ Within " + str(months_back) + " months - will fetch details")
                    elif debug:
                        print("    - Outside " + str(months_back) + " months - basic info only")
                    
                except Exception as e:
                    if debug:
                        print("  ✗ Error processing row " + str(idx) + ": " + str(e))
                    continue
            
            if debug:
                print("\n" + "="*80)
                print("STEP 5: FETCHING DETAILED INFO FOR RECENT APPLICATIONS")
                print("="*80)
                apps_to_detail = sum(1 for a in app_links if a['within_range'])
                print("  Will fetch details for " + str(apps_to_detail) + " applications")
            
            results = []
            for idx, app_info in enumerate(app_links, 1):
                result = {
                    'application_number': app_info['application_number'],
                    'lodgement_date': app_info['lodgement_date'],
                    'location': app_info['location'],
                    'application_type': app_info['application_type'],
                    'suburb': app_info['suburb'],
                    'details_fetched': False
                }
                
                if app_info['within_range'] and app_info['href']:
                    if debug:
                        print("\n  [" + str(idx) + "/" + str(len(app_links)) + "] Fetching details for " + app_info['application_number'] + "...")
                    
                    try:
                        if page.url != results_url:
                            page.goto(results_url)
                            page.wait_for_load_state('networkidle')
                            time.sleep(2)
                        
                        if debug:
                            print("    Clicking application link...")
                        
                        app_link = page.query_selector('a:has-text("' + app_info['application_number'] + '")')
                        if app_link:
                            app_link.click()
                            page.wait_for_load_state('networkidle')
                            time.sleep(2)
                            
                            if debug:
                                print("    ✓ On detail page: " + page.url)
                            
                            if 'Error.aspx' in page.url:
                                if debug:
                                    print("    ✗ Got error page")
                                result['error'] = 'Session expired or access denied'
                            else:
                                page.wait_for_selector('fieldset legend:has-text("Details")', timeout=5000)
                                
                                page_html = page.content()
                                
                                description = None
                                status = None
                                
                                try:
                                    # Pattern that matches the actual HTML structure with <div> wrapper
                                    # Application description
                                    desc_pattern = r'Application description</span><div class="AlternateContentText"[^>]*>([^<]+(?:<[^/][^>]*>[^<]*</[^>]+>)*[^<]*)</div>'
                                    desc_match = re.search(desc_pattern, page_html, re.IGNORECASE | re.DOTALL)
                                    if desc_match:
                                        description = re.sub(r'<[^>]+>', '', desc_match.group(1)).strip()
                                        # Clean up extra whitespace and newlines
                                        description = ' '.join(description.split())
                                        if debug:
                                            print("    ✓ Found description: " + description[:80] + "...")
                                    
                                    # Status
                                    status_pattern = r'Status</span><div class="AlternateContentText"[^>]*>([^<]+(?:<[^/][^>]*>[^<]*</[^>]+>)*[^<]*)</div>'
                                    status_match = re.search(status_pattern, page_html, re.IGNORECASE | re.DOTALL)
                                    if status_match:
                                        status = re.sub(r'<[^>]+>', '', status_match.group(1)).strip()
                                        status = ' '.join(status.split())
                                        if debug:
                                            print("    ✓ Found status: " + status)
                                            
                                except Exception as e:
                                    if debug:
                                        print("    - Regex extraction error: " + str(e))
                                
                                if description:
                                    result['application_description'] = description
                                else:
                                    if debug:
                                        print("    ✗ Could not find description")
                                
                                if status:
                                    result['status'] = status
                                else:
                                    if debug:
                                        print("    ✗ Could not find status")
                                
                                result['details_fetched'] = True
                            
                            if debug:
                                print("    Navigating back...")
                            page.go_back()
                            page.wait_for_load_state('networkidle')
                            time.sleep(2)
                        
                    except Exception as e:
                        if debug:
                            print("    ✗ ERROR: " + str(e))
                        result['error'] = str(e)
                        
                        try:
                            page.goto(results_url)
                            page.wait_for_load_state('networkidle')
                            time.sleep(2)
                        except:
                            pass
                else:
                    if debug and not app_info['within_range']:
                        print("  [" + str(idx) + "/" + str(len(app_links)) + "] Skipping " + app_info['application_number'] + " (outside date range)")
                
                results.append(result)
            
            if debug:
                print("\n" + "="*80)
                print("SCRAPING COMPLETE")
                print("="*80)
                print("Total applications: " + str(len(results)))
                with_details = sum(1 for r in results if r['details_fetched'])
                print("With detailed info: " + str(with_details))
                print("="*80)
            
            browser.close()
            return results
                
        except Exception as e:
            print("\n" + "="*80)
            print("CRITICAL ERROR")
            print("="*80)
            print("Error: " + str(e))
            try:
                print("Current URL: " + page.url)
            except:
                pass
            
            browser.close()
            return []


def get_development_applications(full_address, months_back=12, debug=False):
    """
    Main API function to get development applications from a full address.
    
    Args:
        full_address: Full address from geocoder (e.g., "12 Aquila Court, MERMAID WATERS, 4218")
        months_back: Only get detailed info for applications within this many months
        debug: Enable verbose debugging output
    
    Returns:
        Dictionary with success status and results or error message
    """
    try:
        # Parse address
        street_number, street_name, street_type, suburb = parse_address(full_address)
        
        if not street_name or not street_type:
            return {
                'success': False,
                'error': 'Could not parse address',
                'address_parsed': {
                    'street_number': street_number,
                    'street_name': street_name,
                    'street_type': street_type,
                    'suburb': suburb
                }
            }
        
        if debug:
            print(f"Parsed address:")
            print(f"  Street Number: {street_number}")
            print(f"  Street Name: {street_name}")
            print(f"  Street Type: {street_type}")
            print(f"  Suburb: {suburb}")
        
        # Scrape PDOnline
        results = scrape_pdonline_with_details(
            street_name=street_name,
            street_type=street_type,
            street_number=street_number,
            months_back=months_back,
            debug=debug
        )
        
        return {
            'success': True,
            'address_parsed': {
                'street_number': street_number,
                'street_name': street_name,
                'street_type': street_type,
                'suburb': suburb
            },
            'results': results,
            'count': len(results)
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }


# Test it
if __name__ == "__main__":
    # Test with geocoder format address
    test_address = "43 Peerless Avenue, MERMAID BEACH, 4218"
    
    print("Testing with address:", test_address)
    print()
    
    response = get_development_applications(test_address, months_back=12, debug=True)
    
    print("\n" + "="*80)
    print("API RESPONSE")
    print("="*80)
    print(f"Success: {response['success']}")
    
    if response['success']:
        print(f"Address parsed: {response['address_parsed']}")
        print(f"Total applications: {response['count']}")
        print()
        
        for i, r in enumerate(response['results'], 1):
            print(f"\n{i}. {r['application_number']}")
            print(f"   Date: {r['lodgement_date']}")
            print(f"   Type: {r['application_type']}")
            if r.get('status'):
                print(f"   Status: {r['status']}")
            if r.get('application_description'):
                desc = r['application_description']
                if len(desc) > 100:
                    print(f"   Description: {desc[:100]}...")
                else:
                    print(f"   Description: {desc}")
    else:
        print(f"Error: {response['error']}")
